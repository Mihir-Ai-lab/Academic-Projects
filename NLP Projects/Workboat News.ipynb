{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6372b80c-6d44-4bdd-aec1-0b88c39af60f",
   "metadata": {},
   "source": [
    "# **Table of Contents**\r\n",
    "---\r\n",
    "\r\n",
    "1. [**Introduction**](#Section1)<br>\r\n",
    "   1.1 [**Company Introduction - News Agency**](#Section11)<br>\r\n",
    "   1.2 [**Project Overview**](#Section12)<br>\r\n",
    "   1.3 [**Objectives**](#Section13)<br>\r\n",
    "\r\n",
    "2. [**Data Acquisition and Preparation**](#Section2)<br>\r\n",
    "   2.1 [**Installing and Importing Libraries**](#Section21)<br>\r\n",
    "   2.2 [**Data Acquisition**](#Section22)<br>\r\n",
    "   2.3 [**Data Description and Quality Check**](#Section23)<br>\r\n",
    "   2.4 [**Data Transformation and Cleaning**](#Section24)<br>\r\n",
    "\r\n",
    "3. [**Exploratory Data Analysis (EDA)**](#Section3)<br>\r\n",
    "   3.1 [**Distribution of News Categories**](#Section31)<br>\r\n",
    "   3.2 [**Analysis of Headlines**](#Section32)<br>\r\n",
    "   3.3 [**Analysis of Short Descriptions**](#Section33)<br>\r\n",
    "\r\n",
    "4. [**Text Preprocessing**](#Section4)<br>\r\n",
    "   4.1 [**Cleaning the Text Data**](#Section41)<br>\r\n",
    "   4.2 [**Tokenization**](#Section42)<br>\r\n",
    "   4.3 [**Vectorization**](#Section43)<br>\r\n",
    "\r\n",
    "5. [**Model Building**](#Section5)<br>\r\n",
    "   5.1 [**Baseline Models**](#Section51)<br>\r\n",
    "   5.2 [**Advanced Models**](#Section52)<br>\r\n",
    "   5.3 [**Model Training and Validation**](#Section53)<br>\r\n",
    "   5.4 [**Model Evaluation**](#Section54)<br>\r\n",
    "\r\n",
    "6. [**Model Optimization**](#Section6)<br>\r\n",
    "   6.1 [**Hyperparameter Tuning**](#Section61)<br>\r\n",
    "   6.2 [**Regularization Techniques**](#Section62)<br>\r\n",
    "\r\n",
    "7. [**Final Model and Predictions**](#Section7)<br>\r\n",
    "   7.1 [**Training the Final Model**](#Section71)<br>\r\n",
    "   7.2 [**Making Predictions on Test Set**](#Section72)<br>\r\n",
    "   7.3 [**Creating Submission File**](#Section73)<br>\r\n",
    "\r\n",
    "8. [**News Recommender System**](#Section8)<br>\r\n",
    "   8.1 [**Integration with Classification Model**](#Section81)<br>\r\n",
    "   8.2 [**Fetching Top News Articles**](#Section82)<br>\r\n",
    "\r\n",
    "9. [**Summary of Findings**](#Section9)<br>\r\n",
    "\r\n",
    "10. [**Actionable Insights and Recommendations**](#Section10)<br>\r\n",
    "    10.1 [**Enhancing Personalization**](#Section101)<br>\r\n",
    "    10.2 [**Improving User Engagement**](#Section102)<br>\r\n",
    "\r\n",
    "11. [**Appendix and References**](#Section11)<br>\r\n",
    "    11.1 [**Guide to Text Classification**](https://www.analyticsvidhya.com/blog/2021/06/a-hands-on-guide-to-text-classification/)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53687da7-fc0d-407f-b691-8934cf87ea54",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Section1\"></a>\n",
    "# **1. Introduction**\n",
    "---\n",
    "\n",
    "## 1.1 Company Introduction - Workboat News\n",
    "\n",
    "Workboat News is a prominent player in the media industry, delivering timely and accurate news to a diverse audience. As the media landscape evolves, the News Agency recognizes the need to adapt to modern consumption habits. In an era where digital platforms dominate, the agency aims to provide a personalized and seamless news-reading experience. By leveraging cutting-edge technology, the News Agency seeks to enhance user engagement and ensure that readers receive news content tailored to their interests.\n",
    "\n",
    "## 1.2 Project Overview\n",
    "\n",
    "The objective of this project is to develop a sophisticated news classification model that can categorize news articles into predefined categories. This model will serve as the backbone of a mobile app designed to deliver personalized news content to users. By analyzing headlines and short descriptions, the model will predict the category of each news article, enabling the app to curate news feeds based on user preferences. This project will not only streamline news delivery but also improve user satisfaction by reducing information overload and presenting relevant content.\n",
    "\n",
    "## 1.3 Objectives\n",
    "\n",
    "The key objectives of this project are as follows:\n",
    "\n",
    "- **Acquiring and preparing the necessary data for analysis:** The project involves retrieving and processing a comprehensive dataset containing news categories, headlines, descriptions, dates, and links. This dataset is crucial for training and validating the news classification model.\n",
    "\n",
    "- **Performing exploratory data analysis (EDA) to understand the distribution and characteristics of the data:** The project will conduct an in-depth analysis of the dataset to uncover patterns and trends. This analysis will provide insights into the distribution of news categories, the frequency of different keywords in headlines, and the overall structure of the data.\n",
    "\n",
    "- **Implementing text preprocessing techniques to clean and prepare the text data:** The project will involve cleaning the text data by removing unnecessary characters, punctuation, and stop words. It will also include tokenization, stemming, and vectorization to convert the text into a suitable format for model training.\n",
    "\n",
    "- **Building and evaluating a text classification model to categorize news articles:** The project will explore various machine learning and deep learning models, such as Naive Bayes, Logistic Regression, LSTM, GRU, and BERT-based models. The models will be trained and validated using the prepared dataset, and their performance will be evaluated using metrics like accuracy and F1-score.\n",
    "\n",
    "- **Optimizing the model for better performance:** The project will include hyperparameter tuning and regularization techniques to enhance the model's accuracy and prevent overfitting. This step is critical to ensure that the model generalizes well to unseen data.\n",
    "\n",
    "- **Integrating the final model into a news recommender system:** The trained model will be used to classify incoming news articles in real-time. The classified articles will then be passed to a news recommender system, which will fetch and display top news articles based on user preferences.\n",
    "\n",
    "- **Summarizing the findings, providing actionable insights, and making recommendations for future improvements:** The project will conclude with a summary of key findings from the analyses and model evaluations. It will offer actionable insights to the News Agency for enhancing their news delivery platform and suggest areas for future research and model improvements.\n",
    "\n",
    "By achieving these objectives, the project aims to empower the News Agency with a robust and scalable solution for personalized news delivery, enhancing user engagement and satisfaction.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"https://raw.githubusercontent.com/Mihir-Ai-lab/Academic-Projects/main/Images/News Classification.gif\" alt=\"News Classification\" style=\"height:500px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3388bf04-b663-4859-a3ff-5ec5ffc4dc88",
   "metadata": {},
   "source": [
    "---\n",
    "<a name = Section1></a>\n",
    "# **2. Data Preparation and Acquisition**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9718adc-cc23-41d6-87b1-43b8d4aa88a1",
   "metadata": {},
   "source": [
    "<a name = Section21></a>\n",
    "### **2.1 Installing and Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5c21ee7-07c4-4045-965a-e7131346876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q matplotlib seaborn\n",
    "!pip install -q nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "982ff7ee-b64e-4a7d-897d-775b92e289d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mihir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mihir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mihir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os  # For operating system dependent functionality\n",
    "import re  # For regular expressions\n",
    "import time  # For time-related functions\n",
    "import calendar  # For calendar-related functions\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical computations\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "import seaborn as sns  # For data visualization\n",
    "import requests  # For making HTTP requests\n",
    "import zipfile  # For handling zip files\n",
    "import io  # For handling I/O operations\n",
    "import pickle  # For serializing and de-serializing a Python object structure\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset into train and test sets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # For converting text data to TF-IDF feature vectors\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier  # For linear classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix  # For model evaluation\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer  # For lemmatizing words\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Configure pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)  # Display all columns in DataFrame\n",
    "pd.set_option('display.max_colwidth', None)  # Display full width of columns\n",
    "pd.set_option('display.max_rows', None)  # Display all rows in DataFrame\n",
    "pd.set_option('mode.chained_assignment', None)  # Allow chained assignment operations\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)  # Display float values with 2 decimal places\n",
    "\n",
    "# Set numpy print options\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "# Configure matplotlib for inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd3039-9d64-4bf6-9236-4ef2e38ee232",
   "metadata": {},
   "source": [
    "<a name = Section22></a>\n",
    "### **2.2 Data Acquisition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e85f80ff-a1c3-4215-a5cc-81e155f8e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the zipped train data\n",
    "train_url = 'https://raw.githubusercontent.com/Mihir-Ai-lab/Academic-Projects/main/NLP%20Projects/Workboat%20News/Data/Train_data.zip'\n",
    "\n",
    "# Download the zipped file\n",
    "response = requests.get(train_url)\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "# Extract the contents of the zip file\n",
    "zip_file.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4dd77721-8439-4d28-a7d1-087d757714b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the val data\n",
    "test_url = 'https://raw.githubusercontent.com/Mihir-Ai-lab/Academic-Projects/main/NLP%20Projects/Workboat%20News/Data/Test_data.csv'\n",
    "\n",
    "# Download the test file\n",
    "test_data = requests.get(test_url).content\n",
    "\n",
    "# Save the test file\n",
    "with open('data/Test_data.csv', 'wb') as file:\n",
    "    file.write(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0bb4cd94-70c7-48d8-9c56-9ad4498d08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "df_train = pd.read_csv('data/Train_data.csv')\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv('data/Test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "609017a8-eca8-409d-8c78-c72536ea254a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REF_NO</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123291</td>\n",
       "      <td>Putin, Fear and Leadership</td>\n",
       "      <td>James A. Cusumano, Ph.D., ContributorOwner and operator, Chateau Mcely; author, 'Balance'</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/the-similarities-between-_b_5271284.html</td>\n",
       "      <td>There are uncomfortable parallels between Hitler's actions in Czechoslovakia and Putin's moves in the Crimea and Ukraine.</td>\n",
       "      <td>2014-05-08</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37541</td>\n",
       "      <td>Barack Obama Failed To Get A New Climate Law, But His Legacy Might Be Stronger Because Of It</td>\n",
       "      <td>Kate Sheppard</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/barack-obama-climate-legacy_us_586fe435e4b02b5f8588abcc</td>\n",
       "      <td>The fate of climate rules now lies with the Supreme Court.</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REF_NO  \\\n",
       "0  123291   \n",
       "1   37541   \n",
       "\n",
       "                                                                                       headline  \\\n",
       "0                                                                    Putin, Fear and Leadership   \n",
       "1  Barack Obama Failed To Get A New Climate Law, But His Legacy Might Be Stronger Because Of It   \n",
       "\n",
       "                                                                                     authors  \\\n",
       "0  James A. Cusumano, Ph.D., ContributorOwner and operator, Chateau Mcely; author, 'Balance'   \n",
       "1                                                                              Kate Sheppard   \n",
       "\n",
       "                                                                                           link  \\\n",
       "0                 https://www.huffingtonpost.com/entry/the-similarities-between-_b_5271284.html   \n",
       "1  https://www.huffingtonpost.com/entry/barack-obama-climate-legacy_us_586fe435e4b02b5f8588abcc   \n",
       "\n",
       "                                                                                                           short_description  \\\n",
       "0  There are uncomfortable parallels between Hitler's actions in Czechoslovakia and Putin's moves in the Crimea and Ukraine.   \n",
       "1                                                                 The fate of climate rules now lies with the Supreme Court.   \n",
       "\n",
       "         date  category  \n",
       "0  2014-05-08  POLITICS  \n",
       "1  2017-01-11  POLITICS  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c0a51cf-a0bc-4ff4-b7c9-1bacebde65d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REF_NO</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146508</td>\n",
       "      <td>Lindsay Lohan Clarifies Venice Film Festival Absence: 'My Focus Is On My Health And Well-Being'</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/lindsay-lohan-venice-film-fest-festival-absence_us_5bb43795e4b066f8d2565f7e</td>\n",
       "      <td>Lohan had already expressed her support for her \"Canyons\" colleagues from across international lines, but this time she felt</td>\n",
       "      <td>2013-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90083</td>\n",
       "      <td>Marco Rubio and the Challenge to Hillary Clinton</td>\n",
       "      <td>Hoyt Hilsman, ContributorAuthor, journalist and former Congressional candidate</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/marco-rubio-and-the-chall_b_7436882.html</td>\n",
       "      <td>The conventional wisdom among Democrats is that Rubio's departures from Republican orthodoxy will doom him in the primaries. This is a curious strategy for Democrats since it relies on the Republican right to rescue Clinton from a formidable opponent. It also is likely wrong.</td>\n",
       "      <td>2015-05-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REF_NO  \\\n",
       "0  146508   \n",
       "1   90083   \n",
       "\n",
       "                                                                                          headline  \\\n",
       "0  Lindsay Lohan Clarifies Venice Film Festival Absence: 'My Focus Is On My Health And Well-Being'   \n",
       "1                                                 Marco Rubio and the Challenge to Hillary Clinton   \n",
       "\n",
       "                                                                          authors  \\\n",
       "0                                                                         Unknown   \n",
       "1  Hoyt Hilsman, ContributorAuthor, journalist and former Congressional candidate   \n",
       "\n",
       "                                                                                                               link  \\\n",
       "0  https://www.huffingtonpost.com/entry/lindsay-lohan-venice-film-fest-festival-absence_us_5bb43795e4b066f8d2565f7e   \n",
       "1                                     https://www.huffingtonpost.com/entry/marco-rubio-and-the-chall_b_7436882.html   \n",
       "\n",
       "                                                                                                                                                                                                                                                                      short_description  \\\n",
       "0                                                                                                                                                          Lohan had already expressed her support for her \"Canyons\" colleagues from across international lines, but this time she felt   \n",
       "1  The conventional wisdom among Democrats is that Rubio's departures from Republican orthodoxy will doom him in the primaries. This is a curious strategy for Democrats since it relies on the Republican right to rescue Clinton from a formidable opponent. It also is likely wrong.   \n",
       "\n",
       "         date  \n",
       "0  2013-08-31  \n",
       "1  2015-05-25  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf99f3-b94e-4dd4-affb-ed57ea0bd27b",
   "metadata": {},
   "source": [
    "<a name = Section23></a>\n",
    "### **2.2 Data Description & Quality check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0611648-a9d6-4c4a-b577-6e8e6a912550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (160682, 7)\n",
      "Validation Data Shape: (40171, 6)\n"
     ]
    }
   ],
   "source": [
    "print('Training Data Shape:',df_train.shape)\n",
    "print('Validation Data Shape:',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c28c1a0a-40ff-49f5-9684-ec181852c453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160682 entries, 0 to 160681\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   REF_NO             160682 non-null  int64 \n",
      " 1   headline           160676 non-null  object\n",
      " 2   authors            160682 non-null  object\n",
      " 3   link               160682 non-null  object\n",
      " 4   short_description  144885 non-null  object\n",
      " 5   date               160682 non-null  object\n",
      " 6   category           160682 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d631570-35f8-45c1-aa0d-4db6a25a0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date to the right format\n",
    "\n",
    "df_train[\"date\"] = pd.to_datetime(df_train[\"date\"])\n",
    "df_train[\"date\"] = pd.to_datetime(df_train[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66dc564f-5b4d-4063-bd2d-959b928b8e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data from: 28th January 2012\n",
      "Training Data collected up to: 26th May 2018\n",
      "Time Span: from 28th January 2012 to 26th May 2018\n"
     ]
    }
   ],
   "source": [
    "# Getting the details about when the data was collected\n",
    "\n",
    "start_date = df_train['date'].min().strftime('%dth %B %Y')\n",
    "end_date = df_train['date'].max().strftime('%dth %B %Y')\n",
    "\n",
    "print(f\"Training Data from: {start_date}\")\n",
    "print(f\"Training Data collected up to: {end_date}\")\n",
    "print(f\"Time Span: from {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b0c0e-fa03-48c6-a9cf-ffd2cb5ef9a9",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6f43eb9-0f3f-46cc-872b-4cb935cb75db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in train data:\n",
      "REF_NO                   0\n",
      "headline                 6\n",
      "authors                  0\n",
      "link                     0\n",
      "short_description    15797\n",
      "date                     0\n",
      "category                 0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data:\n",
      "REF_NO                  0\n",
      "headline                0\n",
      "authors                 0\n",
      "link                    0\n",
      "short_description    3915\n",
      "date                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in train data:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1b2a604d-78e5-4bc8-896c-8ee92d37adbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in train data after cleaning:\n",
      "REF_NO               0\n",
      "headline             0\n",
      "authors              0\n",
      "link                 0\n",
      "short_description    0\n",
      "date                 0\n",
      "category             0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data after cleaning:\n",
      "REF_NO               0\n",
      "headline             0\n",
      "authors              0\n",
      "link                 0\n",
      "short_description    0\n",
      "date                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "df_train = df_train.dropna()\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "# Verify there are no missing values left\n",
    "print(\"\\nMissing values in train data after cleaning:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test data after cleaning:\")\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b857b1-834b-4d1c-87bd-c5515895ffcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
